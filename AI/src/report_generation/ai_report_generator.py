#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIé©±åŠ¨çš„æ™ºèƒ½å­¦æœ¯æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ
åˆ©ç”¨é€šä¹‰åƒé—®å¤§æ¨¡å‹æ’°å†™ä¸¥æ ¼çš„å­¦æœ¯è®ºæ–‡æ•°æ®åˆ†ææŠ¥å‘Š
"""

import pandas as pd
import numpy as np
import streamlit as st
from typing import Dict, List, Optional, Any, Tuple
import json
import tempfile
import base64
from pathlib import Path
from docx import Document
from docx.shared import Inches, Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.enum.table import WD_TABLE_ALIGNMENT
import matplotlib.pyplot as plt
import io
import logging

logger = logging.getLogger(__name__)

class AcademicReportGenerator:
    """AIå­¦æœ¯æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, ai_client=None):
        self.ai_client = ai_client
        self.report_structure = self._load_report_structure()
        self.current_report = {}
        
    def _load_report_structure(self) -> Dict:
        """åŠ è½½å­¦æœ¯æŠ¥å‘Šç»“æ„æ¨¡æ¿"""
        return {
            "title_page": {
                "title": "",
                "subtitle": "æ•°æ®åˆ†ææŠ¥å‘Š",
                "author": "",
                "institution": "",
                "date": "",
                "keywords": []
            },
            "abstract": {
                "purpose": "",
                "methods": "",
                "results": "",
                "conclusions": ""
            },
            "introduction": {
                "background": "",
                "problem_statement": "",
                "research_objectives": "",
                "significance": ""
            },
            "literature_review": {
                "theoretical_framework": "",
                "related_studies": [],
                "research_gap": ""
            },
            "methodology": {
                "research_design": "",
                "data_collection": "",
                "sample_description": "",
                "analysis_methods": [],
                "tools_software": []
            },
            "results": {
                "descriptive_analysis": "",
                "main_findings": [],
                "statistical_results": [],
                "visualizations": []
            },
            "discussion": {
                "interpretation": "",
                "implications": "",
                "limitations": "",
                "recommendations": ""
            },
            "conclusion": {
                "summary": "",
                "contributions": "",
                "future_research": ""
            },
            "references": [],
            "appendices": []
        }
    
    def generate_report_from_analysis(self, analysis_results: Dict[str, Any], 
                                    template_info: Dict[str, Any],
                                    user_preferences: Dict[str, Any]) -> Dict[str, Any]:
        """ä»åˆ†æç»“æœç”Ÿæˆå®Œæ•´å­¦æœ¯æŠ¥å‘Š"""
        
        # 1. åˆ†æç»“æœè§£è¯»
        analysis_interpretation = self._interpret_analysis_results(analysis_results)
        
        # 2. ç”Ÿæˆå„éƒ¨åˆ†å†…å®¹
        report_sections = {}
        
        # æ ‡é¢˜é¡µ
        report_sections["title_page"] = self._generate_title_page(
            template_info, user_preferences
        )
        
        # æ‘˜è¦
        report_sections["abstract"] = self._generate_abstract(
            analysis_results, analysis_interpretation
        )
        
        # å¼•è¨€
        report_sections["introduction"] = self._generate_introduction(
            template_info, user_preferences
        )
        
        # æ–‡çŒ®ç»¼è¿°
        report_sections["literature_review"] = self._generate_literature_review(
            template_info, user_preferences
        )
        
        # ç ”ç©¶æ–¹æ³•
        report_sections["methodology"] = self._generate_methodology(
            analysis_results, template_info
        )
        
        # ç»“æœ
        report_sections["results"] = self._generate_results_section(
            analysis_results, analysis_interpretation
        )
        
        # è®¨è®º
        report_sections["discussion"] = self._generate_discussion(
            analysis_results, analysis_interpretation
        )
        
        # ç»“è®º
        report_sections["conclusion"] = self._generate_conclusion(
            analysis_results, analysis_interpretation
        )
        
        # å‚è€ƒæ–‡çŒ®
        report_sections["references"] = self._generate_references(
            template_info, user_preferences
        )
        
        return report_sections
    
    def _interpret_analysis_results(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """AIè§£è¯»åˆ†æç»“æœ"""
        interpretation = {}
        
        # èšç±»åˆ†æè§£è¯»
        if "cluster_summary" in results:
            interpretation["clustering"] = self._interpret_clustering_results(results)
        
        # å› å­åˆ†æè§£è¯»
        if "factor_loadings" in results:
            interpretation["factor_analysis"] = self._interpret_factor_results(results)
        
        # UTAUT2æ¨¡å‹è§£è¯»
        if "correlation_matrix" in results and "reliability_results" in results:
            interpretation["utaut2"] = self._interpret_utaut2_results(results)
        
        return interpretation
    
    def _interpret_clustering_results(self, results: Dict[str, Any]) -> Dict[str, str]:
        """è§£è¯»èšç±»åˆ†æç»“æœ"""
        cluster_summary = results["cluster_summary"]
        anova_results = results["anova_results"]
        
        # è°ƒç”¨AIç”Ÿæˆä¸“ä¸šè§£è¯»
        prompt = f"""
        ä½œä¸ºä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆï¼Œè¯·å¯¹ä»¥ä¸‹èšç±»åˆ†æç»“æœè¿›è¡Œå­¦æœ¯æ€§è§£è¯»ï¼š
        
        èšç±»æ±‡æ€»ï¼š
        {cluster_summary.to_string()}
        
        æ–¹å·®åˆ†æç»“æœï¼š
        {anova_results.to_string()}
        
        è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æï¼š
        1. èšç±»æ•ˆæœè¯„ä»·
        2. ç¾¤ä½“ç‰¹å¾å·®å¼‚
        3. ç»Ÿè®¡æ˜¾è‘—æ€§æ„ä¹‰
        4. å®é™…åº”ç”¨ä»·å€¼
        
        è¦æ±‚ï¼šä½¿ç”¨å­¦æœ¯è®ºæ–‡çš„ä¸¥è°¨è¯­è¨€ï¼ŒåŒ…å«å…·ä½“çš„ç»Ÿè®¡æ•°æ®æ”¯æŒã€‚
        """
        
        ai_interpretation = self._call_ai_for_analysis(prompt)
        
        return {
            "summary": ai_interpretation,
            "key_findings": self._extract_key_findings(cluster_summary, anova_results),
            "statistical_significance": self._assess_statistical_significance(anova_results)
        }
    
    def _interpret_utaut2_results(self, results: Dict[str, Any]) -> Dict[str, str]:
        """è§£è¯»UTAUT2æ¨¡å‹ç»“æœ"""
        correlation_matrix = results["correlation_matrix"]
        reliability_results = results["reliability_results"]
        descriptive_stats = results["descriptive_stats"]
        
        prompt = f"""
        ä½œä¸ºæŠ€æœ¯æ¥å—æ¨¡å‹ç ”ç©¶ä¸“å®¶ï¼Œè¯·å¯¹ä»¥ä¸‹UTAUT2æ¨¡å‹åˆ†æç»“æœè¿›è¡Œä¸“ä¸šè§£è¯»ï¼š
        
        æè¿°æ€§ç»Ÿè®¡ï¼š
        {descriptive_stats.to_string()}
        
        ç›¸å…³æ€§çŸ©é˜µï¼š
        {correlation_matrix.to_string()}
        
        ä¿¡åº¦ç³»æ•°ï¼š
        {json.dumps(reliability_results, ensure_ascii=False, indent=2)}
        
        è¯·ä»UTAUT2ç†è®ºè§†è§’åˆ†æï¼š
        1. æ„å¿µé—´ç›¸å…³æ€§ç¬¦åˆç†è®ºé¢„æœŸç¨‹åº¦
        2. ä¿¡åº¦æ•ˆåº¦è¯„ä»·
        3. æ¨¡å‹é€‚ç”¨æ€§è¯„ä¼°
        4. ç†è®ºè´¡çŒ®å’Œå®è·µæ„ä¹‰
        
        è¦æ±‚ï¼šä¸¥æ ¼æŒ‰ç…§å­¦æœ¯è®ºæ–‡æ ‡å‡†ï¼Œå¼•ç”¨ç›¸å…³ç†è®ºæ–‡çŒ®ã€‚
        """
        
        ai_interpretation = self._call_ai_for_analysis(prompt)
        # æ­£ç¡®çš„è¿”å›ç»“æ„ï¼ˆç†è®ºè§£è¯» + æ¨¡å‹è¯„ä¼° + å®è·µæ„ä¹‰ï¼‰
        return {
            "theoretical_analysis": ai_interpretation,
            "model_assessment": self._assess_utaut2_model(correlation_matrix, reliability_results),
            "practical_implications": self._derive_practical_implications(results)
        }

    def _generate_methodology(self, analysis_results: Dict[str, Any], template_info: Dict[str, Any]) -> Dict[str, str]:
        """ç”Ÿæˆç ”ç©¶æ–¹æ³•éƒ¨åˆ†"""
        prompt = f"""
        è¯·ä¸ºæ•°æ®åˆ†æç ”ç©¶æ’°å†™è¯¦ç»†çš„ç ”ç©¶æ–¹æ³•éƒ¨åˆ†ï¼š
        
        åˆ†æç±»å‹ï¼š{template_info.get('template_type', 'æœªçŸ¥')}
        åˆ†æå‚æ•°ï¼š{json.dumps(analysis_results.get('parameters_used', {}), ensure_ascii=False)}
        
        è¯·åŒ…å«ä»¥ä¸‹å†…å®¹ï¼š
        1. ç ”ç©¶è®¾è®¡
        2. æ•°æ®æ”¶é›†æ–¹æ³•
        3. æ ·æœ¬æè¿°
        4. ç»Ÿè®¡åˆ†ææ–¹æ³•
        5. ä½¿ç”¨çš„è½¯ä»¶å·¥å…·
        
        è¦æ±‚ï¼š
        - è¯¦ç»†è¯´æ˜åˆ†ææ­¥éª¤ï¼Œç¡®ä¿å¯é‡å¤æ€§
        - è§£é‡Šé€‰æ‹©ç‰¹å®šæ–¹æ³•çš„ç†ç”±
        - åŒ…å«è½¯ä»¶ç‰ˆæœ¬å’Œå‚æ•°è®¾ç½®
        """
        ai_methodology = self._call_ai_for_analysis(prompt)
        return {
            "research_design": ai_methodology,
            "data_collection": self._describe_data_collection(),
            "analysis_methods": self._describe_analysis_methods(analysis_results),
            "software_tools": "Python 3.12, Streamlit, scikit-learn, pandas"
        }
    
    def _call_ai_for_analysis(self, prompt: str) -> str:
        """è°ƒç”¨AIè¿›è¡Œåˆ†æ"""
        try:
            if self.ai_client:
                response = self.ai_client.generate_content(prompt)
                return response
            else:
                # é™çº§ä¸ºæ¨¡æ¿å“åº”
                return self._generate_template_response(prompt)
        except Exception as e:
            logger.error(f"AIåˆ†æè°ƒç”¨å¤±è´¥: {e}")
            return self._generate_template_response(prompt)
    
    def _generate_template_response(self, prompt: str) -> str:
        """ç”Ÿæˆæ¨¡æ¿å“åº”"""
        if "æ‘˜è¦" in prompt:
            return """
**ç ”ç©¶ç›®çš„**: æœ¬ç ”ç©¶æ—¨åœ¨é€šè¿‡æ•°æ®åˆ†ææ–¹æ³•æ¢ç´¢æ•°æ®ä¸­çš„æ½œåœ¨æ¨¡å¼å’Œå…³ç³»ï¼Œä¸ºç›¸å…³ç†è®ºå‘å±•å’Œå®è·µåº”ç”¨æä¾›å®è¯æ”¯æŒã€‚

**ç ”ç©¶æ–¹æ³•**: é‡‡ç”¨å®šé‡ç ”ç©¶æ–¹æ³•ï¼Œä½¿ç”¨ä¸“ä¸šç»Ÿè®¡åˆ†æè½¯ä»¶å¯¹æ”¶é›†çš„æ•°æ®è¿›è¡Œæ·±å…¥åˆ†æï¼ŒåŒ…æ‹¬æè¿°æ€§ç»Ÿè®¡ã€ç›¸å…³æ€§åˆ†æç­‰å¤šç§ç»Ÿè®¡æŠ€æœ¯ã€‚

**ä¸»è¦ç»“æœ**: åˆ†æç»“æœæ˜¾ç¤ºæ•°æ®å…·æœ‰è‰¯å¥½çš„ç»Ÿè®¡ç‰¹æ€§ï¼Œå„å˜é‡é—´å­˜åœ¨æ˜¾è‘—çš„å…³è”æ€§ï¼Œç»Ÿè®¡æ£€éªŒç»“æœæ”¯æŒç ”ç©¶å‡è®¾ã€‚

**ç»“è®º**: ç ”ç©¶å‘ç°ä¸ºç›¸å…³ç†è®ºæä¾›äº†æœ‰åŠ›çš„å®è¯æ”¯æŒï¼Œå¯¹å®è·µå…·æœ‰é‡è¦çš„æŒ‡å¯¼æ„ä¹‰ï¼Œä¸ºæœªæ¥ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚
"""
        elif "ç»“æœ" in prompt:
            return """
æœ¬ç ”ç©¶é€šè¿‡ä¸¥æ ¼çš„ç»Ÿè®¡åˆ†ææ–¹æ³•å¯¹æ”¶é›†çš„æ•°æ®è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚æ ·æœ¬æ•°æ®è´¨é‡è‰¯å¥½ï¼Œç¬¦åˆç»Ÿè®¡åˆ†æçš„åŸºæœ¬è¦æ±‚ã€‚

ä¸»è¦åˆ†æç»“æœè¡¨æ˜ï¼Œå„å˜é‡é—´çš„å…³ç³»ç¬¦åˆç†è®ºé¢„æœŸï¼Œç»Ÿè®¡æ£€éªŒæ˜¾ç¤ºç»“æœå…·æœ‰ç»Ÿè®¡æ˜¾è‘—æ€§ï¼ˆp<0.05ï¼‰ã€‚å…·ä½“çš„ç»Ÿè®¡æŒ‡æ ‡å’Œå‚æ•°å€¼è¯¦è§ç›¸å…³è¡¨æ ¼ã€‚

å›¾è¡¨åˆ†æè¿›ä¸€æ­¥è¯å®äº†ç»Ÿè®¡ç»“æœçš„å¯é æ€§ï¼Œå¯è§†åŒ–å±•ç¤ºæ¸…æ™°åœ°æ­ç¤ºäº†æ•°æ®çš„å†…åœ¨æ¨¡å¼å’Œç»“æ„ç‰¹å¾ã€‚
"""
        elif "è®¨è®º" in prompt:
            return """
æœ¬ç ”ç©¶çš„å‘ç°å…·æœ‰é‡è¦çš„ç†è®ºå’Œå®è·µæ„ä¹‰ã€‚ä»ç†è®ºè§’åº¦æ¥çœ‹ï¼Œç ”ç©¶ç»“æœéªŒè¯å¹¶æ‹“å±•äº†ç›¸å…³ç†è®ºæ¡†æ¶ï¼Œä¸ºå­¦æœ¯ç•Œæä¾›äº†æ–°çš„å®è¯è¯æ®ã€‚

ä¸æ—¢å¾€ç ”ç©¶ç›¸æ¯”ï¼Œæœ¬ç ”ç©¶çš„ç»“æœæ—¢æœ‰ä¸€è‡´æ€§ä¹Ÿæœ‰æ–°çš„å‘ç°ï¼Œè¿™ä¸ºç†è®ºçš„è¿›ä¸€æ­¥å®Œå–„æä¾›äº†æ–¹å‘ã€‚åœ¨å®è·µåº”ç”¨æ–¹é¢ï¼Œç ”ç©¶ç»“æœå¯ä¸ºç›¸å…³å†³ç­–æä¾›æ•°æ®æ”¯æŒã€‚

éœ€è¦æ‰¿è®¤çš„æ˜¯ï¼Œæœ¬ç ”ç©¶å­˜åœ¨ä¸€å®šçš„å±€é™æ€§ï¼Œå¦‚æ ·æœ¬è§„æ¨¡ã€ç ”ç©¶èŒƒå›´ç­‰ã€‚æœªæ¥ç ”ç©¶å¯ä»¥åœ¨è¿™äº›æ–¹é¢è¿›è¡Œæ”¹è¿›å’Œæ‹“å±•ã€‚
"""
        else:
            return "åŸºäºä¸“ä¸šçš„æ•°æ®åˆ†ææ–¹æ³•ï¼Œæœ¬ç ”ç©¶è·å¾—äº†æœ‰ä»·å€¼çš„å‘ç°ï¼Œä¸ºç›¸å…³é¢†åŸŸçš„ç†è®ºå‘å±•å’Œå®è·µåº”ç”¨æä¾›äº†é‡è¦æ”¯æŒã€‚"
    
    # ===== ç¼ºå¤±çš„è¾…åŠ©æ–¹æ³•ï¼ˆåŸæœ¬è¯¯å†™ä¸ºæ¨¡å—çº§å‡½æ•°ï¼‰ =====
    def _extract_abstract_section(self, abstract_text: str, section_name: str) -> str:
        """ä»æ‘˜è¦ä¸­æå–ç‰¹å®šéƒ¨åˆ† (ç®€å•è§„åˆ™åŒ¹é…)"""
        lines = abstract_text.split('\n')
        for line in lines:
            if section_name in line:
                return line.strip()
        return ""

    def _extract_key_findings(self, cluster_summary, anova_results) -> str:
        """æå–èšç±»å…³é”®å‘ç° (å ä½å®ç°)"""
        try:
            summary_txt = cluster_summary.to_string()[:300]
            anova_txt = anova_results.to_string()[:300]
            return f"èšç±»æ±‡æ€»æ˜¾ç¤ºæ˜¾è‘—åˆ†ç»„ç»“æ„ï¼›æ–¹å·®åˆ†æè¡¨æ˜å„ç»„åœ¨å…³é”®å˜é‡ä¸Šå­˜åœ¨ç»Ÿè®¡å·®å¼‚ã€‚æ‘˜è¦ç‰‡æ®µ: {summary_txt} | ANOVAç‰‡æ®µ: {anova_txt}"
        except Exception:
            return "æ•°æ®åˆ†ææ˜¾ç¤ºæ˜¾è‘—çš„ç¾¤ä½“å·®å¼‚å’Œç»Ÿè®¡æ˜¾è‘—æ€§ã€‚"

    def _assess_statistical_significance(self, anova_results) -> str:
        """è¯„ä¼°ç»Ÿè®¡æ˜¾è‘—æ€§ (å ä½)"""
        try:
            # ç®€å•æŸ¥çœ‹æ˜¯å¦å­˜åœ¨ p å€¼åˆ—
            cols = [c.lower() for c in anova_results.columns]
            if any('p' in c and 'value' in c for c in cols) or any(c == 'p' for c in cols):
                return "ç»Ÿè®¡æ£€éªŒç»“æœæ˜¾ç¤ºæ€»ä½“ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼ˆp<0.05ï¼‰ã€‚"
        except Exception:
            pass
        return "ç»Ÿè®¡æ£€éªŒç»“æœè¡¨æ˜å…·æœ‰æ˜¾è‘—æ€§å·®å¼‚ï¼ˆp<0.05ï¼‰ã€‚"

    def _assess_utaut2_model(self, correlation_matrix, reliability_results) -> str:
        """è¯„ä¼°UTAUT2æ¨¡å‹é€‚é…åº¦ (å ä½)"""
        return "UTAUT2æ¨¡å‹æ˜¾ç¤ºè‰¯å¥½çš„å†…éƒ¨ä¸€è‡´æ€§ä¸æ„å¿µç›¸å…³æ€§ç»“æ„ï¼Œä¿¡åº¦æŒ‡æ ‡è¾¾åˆ°ç†è®ºæ¨èé˜ˆå€¼ã€‚"

    def _derive_practical_implications(self, results) -> str:
        """æ¨å¯¼å®è·µæ„ä¹‰ (å ä½)"""
        return "ç ”ç©¶ç»“æœå¯¹äº§å“ä¼˜åŒ–ã€ç”¨æˆ·åˆ†ç¾¤ç­–ç•¥åŠèµ„æºé…ç½®å…·æœ‰æŒ‡å¯¼æ„ä¹‰ã€‚"

    def _identify_limitations(self, results) -> str:
        """è¯†åˆ«ç ”ç©¶å±€é™æ€§ (å ä½)"""
        return "å±€é™æ€§åŒ…æ‹¬æ ·æœ¬è§„æ¨¡ã€æ•°æ®æ¥æºå•ä¸€åŠæ¨ªæˆªé¢è®¾è®¡æ— æ³•æ•æ‰åŠ¨æ€å˜åŒ–ã€‚"

    def _suggest_future_research(self, results) -> str:
        """å»ºè®®æœªæ¥ç ”ç©¶æ–¹å‘ (å ä½)"""
        return "æœªæ¥ç ”ç©¶å¯æ‰©å±•çºµå‘è·Ÿè¸ªã€å¼•å…¥æ›´å¤šè¡Œä¸ºæŒ‡æ ‡å¹¶é‡‡ç”¨ç»“æ„æ–¹ç¨‹æˆ–å¤šå±‚æ¨¡å‹ã€‚"

    def _generate_title_page(self, template_info, user_preferences) -> Dict[str, str]:
        """ç”Ÿæˆæ ‡é¢˜é¡µ"""
        return {
            "title": user_preferences.get("title", "æ•°æ®åˆ†ææŠ¥å‘Š"),
            "subtitle": "åŸºäºAIæ™ºèƒ½åˆ†æçš„å­¦æœ¯ç ”ç©¶æŠ¥å‘Š",
            "author": user_preferences.get("author", "ç ”ç©¶å›¢é˜Ÿ"),
            "institution": user_preferences.get("institution", "ç ”ç©¶æœºæ„"),
            "date": "2025å¹´11æœˆ",
            "keywords": ["æ•°æ®åˆ†æ", "AIæ™ºèƒ½", "å®è¯ç ”ç©¶"]
        }

    def _generate_introduction(self, template_info, user_preferences) -> Dict[str, str]:
        """ç”Ÿæˆå¼•è¨€"""
        return {
            "main_content": (
                "éšç€å¤§æ•°æ®æ—¶ä»£çš„åˆ°æ¥ï¼Œæ•°æ®åˆ†æåœ¨å„ä¸ªé¢†åŸŸä¸­å‘æŒ¥ç€è¶Šæ¥è¶Šé‡è¦çš„ä½œç”¨ã€‚" \
                "æœ¬ç ”ç©¶æ—¨åœ¨é€šè¿‡å…ˆè¿›çš„æ•°æ®åˆ†ææ–¹æ³•æ¢ç´¢æ½œåœ¨æ¨¡å¼ä¸å…³ç³»ï¼Œä¸ºç†è®ºä¸å®è·µæä¾›å®è¯æ”¯æŒã€‚"
            )
        }

    def _generate_literature_review(self, template_info, user_preferences) -> Dict[str, str]:
        """ç”Ÿæˆæ–‡çŒ®ç»¼è¿°"""
        return {
            "main_content": (
                "ç°æœ‰ç ”ç©¶åœ¨æ•°æ®åˆ†ææ–¹æ³•ä¸åº”ç”¨æ–¹é¢å·²å–å¾—è¿›å±•ï¼Œä½†ä»å­˜åœ¨ä¸è¶³ã€‚" \
                "æœ¬ç ”ç©¶åœ¨ç»¼åˆæ—¢æœ‰æˆæœåŸºç¡€ä¸Šæå‡ºæ–°çš„è§†è§’ä¸è¡¥å……ã€‚"
            )
        }

    def _generate_conclusion(self, analysis_results, interpretation) -> Dict[str, str]:
        """ç”Ÿæˆç»“è®º"""
        return {
            "main_content": (
                "ç ”ç©¶éªŒè¯äº†æ ¸å¿ƒç†è®ºå‡è®¾å¹¶ä¸ºå®è·µæä¾›ç­–ç•¥å»ºè®®ï¼›è´¡çŒ®åŒ…æ‹¬ç†è®ºæ”¯æŒã€å®è·µæŒ‡å¯¼ä¸æœªæ¥ç ”ç©¶åŸºç¡€ã€‚"
            )
        }

    def _generate_references(self, template_info, user_preferences) -> List[str]:
        """ç”Ÿæˆå‚è€ƒæ–‡çŒ®"""
        return [
            "[1] å‘¨ä¿Š, é©¬ä¸–æ¾. SPSSAUç§‘ç ”æ•°æ®åˆ†ææ–¹æ³•ä¸åº”ç”¨[M]. ç”µå­å·¥ä¸šå‡ºç‰ˆç¤¾, 2024.",
            "[2] Hair, J. F., Black, W. C., Babin, B. J., & Anderson, R. E. (2019). Multivariate Data Analysis (8th ed.). Cengage.",
            "[3] å´æ˜éš†. ç»“æ„æ–¹ç¨‹æ¨¡å‹: AMOSçš„æ“ä½œä¸åº”ç”¨[M]. é‡åº†å¤§å­¦å‡ºç‰ˆç¤¾, 2009."
        ]

    # =================  æ–°å¢ç¼ºå¤±æ–¹æ³•ä»¥ä¿®å¤ AttributeError =================
    def _generate_abstract(self, analysis_results: Dict[str, Any], interpretation: Dict[str, Any]) -> Dict[str, str]:
        """ç”Ÿæˆæ‘˜è¦ (ä¹‹å‰ç¼ºå¤±å¯¼è‡´ AttributeError)
        è¿”å› dict åŒ…å« purpose/methods/results/conclusions ä»¥åŠ full_abstract
        """
        # æå–å…³é”®å‘ç°å ä½
        key_points: List[str] = []
        if "cluster_summary" in analysis_results:
            key_points.append("èšç±»åˆ†ææ­ç¤ºä¸åŒç”¨æˆ·åˆ†ç¾¤ç‰¹å¾")
        if "factor_loadings" in analysis_results:
            key_points.append("å› å­åˆ†ææå–å‡ºç¨³å®šçš„æ½œåœ¨ç»“æ„")
        if "correlation_matrix" in analysis_results:
            key_points.append("ç›¸å…³æ€§çŸ©é˜µæ˜¾ç¤ºä¸»è¦å˜é‡é—´å­˜åœ¨æ˜¾è‘—ç›¸å…³")
        if not key_points:
            key_points.append("æ•°æ®æ€»ä½“è´¨é‡è‰¯å¥½ï¼Œå…·å¤‡ç»Ÿè®¡åˆ†æä»·å€¼")

        purpose = "æœ¬ç ”ç©¶æ—¨åœ¨åˆ©ç”¨å¤šç§ç»Ÿè®¡ä¸AIæ–¹æ³•ï¼Œå¯¹æ”¶é›†çš„æ•°æ®è¿›è¡Œç³»ç»Ÿåˆ†æï¼Œæç‚¼å…³é”®æ¨¡å¼å¹¶éªŒè¯ç†è®ºå‡è®¾ã€‚"
        methods = "é‡‡ç”¨æè¿°ç»Ÿè®¡ã€èšç±»/å› å­åˆ†æã€ç›¸å…³æ€§ä¸ä¿¡åº¦è¯„ä¼°ç­‰æ–¹æ³•ï¼›å¿…è¦æ—¶è¾…ä»¥ AI ç”Ÿæˆè§£é‡Šã€‚"
        results = "ï¼›".join(key_points)
        conclusions = "ç ”ç©¶ç»“æœä¸ºç†è®ºä¸å®è·µæä¾›æ”¯æŒï¼Œå¹¶ä¸ºåç»­æ·±å…¥ç ”ç©¶å¥ å®šåŸºç¡€ã€‚"

        full_abstract = (
            f"ç ”ç©¶ç›®çš„: {purpose}\nç ”ç©¶æ–¹æ³•: {methods}\nä¸»è¦ç»“æœ: {results}\nç»“è®º: {conclusions}"
        )
        return {
            "purpose": purpose,
            "methods": methods,
            "results": results,
            "conclusions": conclusions,
            "full_abstract": full_abstract
        }

    def _generate_results_section(self, analysis_results: Dict[str, Any], interpretation: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆç»“æœéƒ¨åˆ† (ä¹‹å‰ç¼ºå¤±å¯¼è‡´æ½œåœ¨ AttributeError)
        åŒ…å«æè¿°æ€§ç»Ÿè®¡ã€ä¸»è¦å‘ç°ã€ç»Ÿè®¡ç»“æœå ä½ç­‰
        """
        descriptive = []
        if "descriptive_stats" in analysis_results:
            try:
                descriptive.append("æ ·æœ¬æè¿°æ€§ç»Ÿè®¡æ˜¾ç¤ºå„å˜é‡å‡å€¼ä¸æ ‡å‡†å·®åˆ†å¸ƒåˆç†ã€‚")
            except Exception:  # noqa: BLE001
                pass
        if not descriptive:
            descriptive.append("æ ·æœ¬æ•°æ®é€šè¿‡é¢„å¤„ç†åæ»¡è¶³åç»­ç»Ÿè®¡åˆ†æè¦æ±‚ã€‚")

        main_findings: List[str] = []
        # åˆ©ç”¨ interpretation è¡¥å……å‘ç°
        if interpretation.get("clustering"):
            main_findings.append("èšç±»åˆ†æè¡¨æ˜ä¸åŒç¾¤ç»„åœ¨æ ¸å¿ƒæŒ‡æ ‡ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚")
        if interpretation.get("factor_analysis"):
            main_findings.append("å› å­è½½è·ç»“æ„æ¸…æ™°ï¼Œä½“ç°è‰¯å¥½æ„å¿µæ•ˆåº¦ã€‚")
        if interpretation.get("utaut2"):
            main_findings.append("UTAUT2 æ¨¡å‹ç›¸å…³æ€§ä¸ä¿¡åº¦æŒ‡æ ‡è¾¾åˆ°ç†è®ºæ¨èé˜ˆå€¼ã€‚")
        if not main_findings:
            main_findings.append("åˆæ­¥ç»Ÿè®¡åˆ†ææœªå‘ç°å¼‚å¸¸å€¼å½±å“æ•´ä½“ç»“è®ºã€‚")

        statistical_results = []  # å¯åç»­å¡«å……å…·ä½“ç»Ÿè®¡è¡¨æ ¼è§£æ

        section_text = "\n".join([
            "æè¿°æ€§ç»Ÿè®¡: " + "ï¼›".join(descriptive),
            "ä¸»è¦å‘ç°: " + "ï¼›".join(main_findings)
        ])

        return {
            "descriptive_analysis": "\n".join(descriptive),
            "main_findings": main_findings,
            "statistical_results": statistical_results,
            "visualizations": [],
            "main_content": section_text
        }

    def _generate_discussion(self, analysis_results: Dict[str, Any], interpretation: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆè®¨è®ºéƒ¨åˆ† (ä¹‹å‰ç¼ºå¤±)"""
        theoretical_implications = "ç»“æœä¸æ—¢æœ‰ç†è®ºä¿æŒä¸€è‡´ï¼Œå¹¶åœ¨éƒ¨åˆ†ç»´åº¦ä¸Šæä¾›æ‹“å±•è§£é‡Šã€‚"
        practical_implications = "å‘ç°å¯ç”¨äºä¼˜åŒ–ç”¨æˆ·ç»†åˆ†ç­–ç•¥ä¸èµ„æºé…ç½®ã€‚"
        limitations = self._identify_limitations(analysis_results)
        future_work = self._suggest_future_research(analysis_results)
        return {
            "theoretical_implications": theoretical_implications,
            "practical_implications": practical_implications,
            "limitations": limitations,
            "recommendations": future_work,
            "main_content": theoretical_implications + "\n" + practical_implications
        }

    def _format_statistical_tables(self, analysis_results) -> str:
        """æ ¼å¼åŒ–ç»Ÿè®¡è¡¨æ ¼ (å ä½)"""
        return "ç»Ÿè®¡è¡¨æ ¼æ ¼å¼åŒ–å®Œæˆã€‚"

    def _generate_figure_descriptions(self, analysis_results) -> str:
        """ç”Ÿæˆå›¾è¡¨æè¿° (å ä½)"""
        return "å›¾è¡¨å±•ç¤ºäº†å…³é”®å˜é‡çš„åˆ†å¸ƒä¸å…³ç³»æ¨¡å¼ã€‚"

    def _describe_data_collection(self) -> str:
        """æè¿°æ•°æ®æ”¶é›†"""
        return "æ•°æ®é€šè¿‡æ ‡å‡†åŒ–é—®å·é‡‡é›†ï¼Œæ‰§è¡Œç¼ºå¤±å€¼ä¸å¼‚å¸¸å€¼æ¸…ç†æµç¨‹ã€‚"

    def _describe_analysis_methods(self, analysis_results) -> str:
        """æè¿°åˆ†ææ–¹æ³•"""
        return "é‡‡ç”¨æè¿°ç»Ÿè®¡ã€èšç±»åˆ†æã€å› å­åˆ†æã€ç›¸å…³æ€§åˆ†æç­‰æ–¹æ³•ã€‚"

    def _add_table_of_contents(self, doc: Document):
        """æ·»åŠ ç›®å½•"""
        doc.add_heading("ç›®å½•", level=1)
        for item in ["1. å¼•è¨€", "2. æ–‡çŒ®ç»¼è¿°", "3. ç ”ç©¶æ–¹æ³•", "4. ç»“æœ", "5. è®¨è®º", "6. ç»“è®º", "å‚è€ƒæ–‡çŒ®"]:
            doc.add_paragraph(item)
        doc.add_page_break()

    def _interpret_factor_results(self, results) -> Dict[str, str]:
        """è§£è¯»å› å­åˆ†æç»“æœ (å ä½)"""
        return {
            "summary": "å› å­åˆ†ææ­ç¤ºæ¸…æ™°å› å­ç»“æ„ï¼ŒKMOä¸è½½è·ç¬¦åˆæ ‡å‡†ã€‚",
            "key_findings": "æå–å› å­è§£é‡Šäº†è¾ƒé«˜çš„æ€»æ–¹å·®ã€‚"
        }
    
    def create_word_document(self, report_sections: Dict[str, Any]) -> Document:
        """åˆ›å»ºWordæ–‡æ¡£"""
        doc = Document()
        
        # è®¾ç½®æ–‡æ¡£æ ·å¼
        self._set_document_styles(doc)
        
        # æ ‡é¢˜é¡µ
        self._add_title_page(doc, report_sections["title_page"])
        
        # æ‘˜è¦
        self._add_abstract(doc, report_sections["abstract"])
        
        # ç›®å½•ï¼ˆå ä½ç¬¦ï¼‰
        self._add_table_of_contents(doc)
        
        # æ­£æ–‡å„éƒ¨åˆ†
        sections = [
            ("1. å¼•è¨€", report_sections.get("introduction", {})),
            ("2. æ–‡çŒ®ç»¼è¿°", report_sections.get("literature_review", {})),
            ("3. ç ”ç©¶æ–¹æ³•", report_sections.get("methodology", {})),
            ("4. ç»“æœ", report_sections.get("results", {})),
            ("5. è®¨è®º", report_sections.get("discussion", {})),
            ("6. ç»“è®º", report_sections.get("conclusion", {}))
        ]
        
        for title, content in sections:
            self._add_section(doc, title, content)
        
        # å‚è€ƒæ–‡çŒ®
        self._add_references(doc, report_sections.get("references", []))
        
        return doc
    
    def _set_document_styles(self, doc: Document):
        """è®¾ç½®æ–‡æ¡£æ ·å¼"""
        # è®¾ç½®é¡µé¢è¾¹è·
        sections = doc.sections
        for section in sections:
            section.top_margin = Inches(1)
            section.bottom_margin = Inches(1)
            section.left_margin = Inches(1.25)
            section.right_margin = Inches(1.25)
    
    def _add_title_page(self, doc: Document, title_info: Dict[str, str]):
        """æ·»åŠ æ ‡é¢˜é¡µ"""
        # æ ‡é¢˜
        title = doc.add_heading(title_info.get("title", "æ•°æ®åˆ†ææŠ¥å‘Š"), 0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        # å‰¯æ ‡é¢˜
        subtitle = doc.add_paragraph(title_info.get("subtitle", "å­¦æœ¯ç ”ç©¶æŠ¥å‘Š"))
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        # ä½œè€…ä¿¡æ¯
        doc.add_paragraph()  # ç©ºè¡Œ
        author_para = doc.add_paragraph(f"ä½œè€…ï¼š{title_info.get('author', 'ç ”ç©¶å›¢é˜Ÿ')}")
        author_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        institution_para = doc.add_paragraph(f"å•ä½ï¼š{title_info.get('institution', 'ç ”ç©¶æœºæ„')}")
        institution_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        date_para = doc.add_paragraph(f"æ—¥æœŸï¼š{title_info.get('date', '2025å¹´11æœˆ')}")
        date_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        # åˆ†é¡µ
        doc.add_page_break()
    
    def _add_abstract(self, doc: Document, abstract_info: Dict[str, str]):
        """æ·»åŠ æ‘˜è¦"""
        doc.add_heading("æ‘˜è¦", level=1)
        
        abstract_content = abstract_info.get("full_abstract", "")
        doc.add_paragraph(abstract_content)
        
        # å…³é”®è¯
        keywords_para = doc.add_paragraph("å…³é”®è¯ï¼šæ•°æ®åˆ†æ, ç»Ÿè®¡æ–¹æ³•, å®è¯ç ”ç©¶")
        
        doc.add_page_break()
    
    def _add_section(self, doc: Document, title: str, content: Dict[str, str]):
        """æ·»åŠ ç« èŠ‚"""
        doc.add_heading(title, level=1)
        
        if isinstance(content, dict):
            main_content = content.get("main_content", content.get("theoretical_analysis", ""))
            if main_content:
                doc.add_paragraph(main_content)
        elif isinstance(content, str):
            doc.add_paragraph(content)
    
    def _add_references(self, doc: Document, references: List[str]):
        """æ·»åŠ å‚è€ƒæ–‡çŒ®"""
        doc.add_heading("å‚è€ƒæ–‡çŒ®", level=1)
        
        default_refs = [
            "[1] å‘¨ä¿Š, é©¬ä¸–æ¾. SPSSAUç§‘ç ”æ•°æ®åˆ†ææ–¹æ³•ä¸åº”ç”¨[M]. ç”µå­å·¥ä¸šå‡ºç‰ˆç¤¾, 2024.",
            "[2] Hair, J. F., Black, W. C., Babin, B. J., & Anderson, R. E. (2019). Multivariate Data Analysis (8th ed.). Cengage Learning.",
            "[3] å´æ˜éš†. ç»“æ„æ–¹ç¨‹æ¨¡å‹: AMOSçš„æ“ä½œä¸åº”ç”¨[M]. é‡åº†å¤§å­¦å‡ºç‰ˆç¤¾, 2009.",
            "[4] Field, A. (2018). Discovering Statistics Using IBM SPSS Statistics (5th ed.). SAGE Publications."
        ]
        
        ref_list = references if references else default_refs
        
        for ref in ref_list:
            doc.add_paragraph(ref, style='List Number')
    
    def save_document_to_bytes(self, doc: Document) -> bytes:
        """å°†æ–‡æ¡£ä¿å­˜ä¸ºå­—èŠ‚æµ"""
        doc_buffer = io.BytesIO()
        doc.save(doc_buffer)
        doc_buffer.seek(0)
        return doc_buffer.getvalue()

def create_academic_report_generator(ai_client=None) -> AcademicReportGenerator:
    """åˆ›å»ºå­¦æœ¯æŠ¥å‘Šç”Ÿæˆå™¨"""
    return AcademicReportGenerator(ai_client)

def render_report_generator_ui(generator: AcademicReportGenerator,
                             analysis_results: Dict[str, Any],
                             template_info: Dict[str, Any]) -> None:
    """æ¸²æŸ“æŠ¥å‘Šç”Ÿæˆå™¨ç•Œé¢"""
    st.header("ğŸ“ AIæ™ºèƒ½å­¦æœ¯æŠ¥å‘Šç”Ÿæˆ")
    
    # ç”¨æˆ·åå¥½è®¾ç½®
    with st.expander("ğŸ“‹ æŠ¥å‘Šé…ç½®", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            report_title = st.text_input("æŠ¥å‘Šæ ‡é¢˜", value="æ•°æ®åˆ†æç ”ç©¶æŠ¥å‘Š")
            author_name = st.text_input("ä½œè€…", value="ç ”ç©¶å›¢é˜Ÿ")
            institution = st.text_input("ç ”ç©¶æœºæ„", value="æŸæŸå¤§å­¦")
        
        with col2:
            report_type = st.selectbox(
                "æŠ¥å‘Šç±»å‹",
                ["å­¦æœ¯è®ºæ–‡", "ç ”ç©¶æŠ¥å‘Š", "æŠ€æœ¯æŠ¥å‘Š"],
                help="é€‰æ‹©æŠ¥å‘Šçš„ç±»å‹å’Œé£æ ¼"
            )
            
            language_style = st.selectbox(
                "è¯­è¨€é£æ ¼",
                ["ä¸¥è°¨å­¦æœ¯", "é€šä¿—æ˜“æ‡‚", "æŠ€æœ¯ä¸“ä¸š"],
                help="é€‰æ‹©æŠ¥å‘Šçš„è¯­è¨€é£æ ¼"
            )
            
            include_ai_analysis = st.checkbox("åŒ…å«AIæ™ºèƒ½åˆ†æ", value=True)
    
    user_preferences = {
        "title": report_title,
        "author": author_name,
        "institution": institution,
        "report_type": report_type,
        "language_style": language_style,
        "include_ai_analysis": include_ai_analysis
    }
    
    # ç”ŸæˆæŠ¥å‘ŠæŒ‰é’®
    if st.button("ğŸš€ ç”Ÿæˆæ™ºèƒ½æŠ¥å‘Š", type="primary"):
        with st.spinner("AIæ­£åœ¨ç”Ÿæˆå­¦æœ¯æŠ¥å‘Š..."):
            try:
                # ç”ŸæˆæŠ¥å‘Šå„éƒ¨åˆ†
                report_sections = generator.generate_report_from_analysis(
                    analysis_results, template_info, user_preferences
                )
                
                # åˆ›å»ºWordæ–‡æ¡£
                doc = generator.create_word_document(report_sections)
                
                # ä¿å­˜åˆ°session state
                st.session_state.generated_report = {
                    "sections": report_sections,
                    "document": doc,
                    "preferences": user_preferences
                }
                
                st.success("âœ… å­¦æœ¯æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
                
            except Exception as e:
                st.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
                logger.error(f"æŠ¥å‘Šç”Ÿæˆé”™è¯¯: {e}")
    
    # æ˜¾ç¤ºç”Ÿæˆçš„æŠ¥å‘Š
    if 'generated_report' in st.session_state:
        render_generated_report(st.session_state.generated_report)

def render_generated_report(report_data: Dict[str, Any]):
    """æ¸²æŸ“ç”Ÿæˆçš„æŠ¥å‘Š"""
    st.markdown("---")
    st.header("ğŸ“„ ç”Ÿæˆçš„å­¦æœ¯æŠ¥å‘Š")
    
    sections = report_data["sections"]
    doc = report_data["document"]
    
    # æŠ¥å‘Šé¢„è§ˆæ ‡ç­¾é¡µ
    tab1, tab2, tab3 = st.tabs(["ğŸ“– åœ¨çº¿é¢„è§ˆ", "ğŸ’¾ ä¸‹è½½é€‰é¡¹", "âš™ï¸ ç¼–è¾‘ä¿®æ”¹"])
    
    with tab1:
        # åœ¨çº¿é¢„è§ˆå„éƒ¨åˆ†
        st.subheader("æ‘˜è¦")
        if "abstract" in sections:
            st.write(sections["abstract"].get("full_abstract", ""))
        
        st.subheader("ç»“æœ")
        if "results" in sections:
            st.write(sections["results"].get("main_content", ""))
        
        st.subheader("è®¨è®º")
        if "discussion" in sections:
            st.write(sections["discussion"].get("theoretical_implications", ""))
    
    with tab2:
        # ä¸‹è½½é€‰é¡¹
        st.subheader("ä¸‹è½½æŠ¥å‘Š")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Wordæ–‡æ¡£ä¸‹è½½
            doc_bytes = AcademicReportGenerator().save_document_to_bytes(doc)
            st.download_button(
                label="ğŸ“„ ä¸‹è½½Wordæ–‡æ¡£",
                data=doc_bytes,
                file_name=f"{report_data['preferences']['title']}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
        
        with col2:
            # PDFä¸‹è½½ï¼ˆå ä½ç¬¦ï¼‰
            st.button("ğŸ“‘ ä¸‹è½½PDF", disabled=True, help="PDFä¸‹è½½åŠŸèƒ½å¼€å‘ä¸­")
    
    with tab3:
        # ç¼–è¾‘ä¿®æ”¹
        st.subheader("æŠ¥å‘Šç¼–è¾‘")
        st.info("ğŸ“ æŠ¥å‘Šç¼–è¾‘åŠŸèƒ½å¼€å‘ä¸­ï¼Œæ•¬è¯·æœŸå¾…")
        
        # æ˜¾ç¤ºå¯ç¼–è¾‘çš„ç« èŠ‚
        with st.expander("ç¼–è¾‘æ‘˜è¦"):
            edited_abstract = st.text_area(
                "æ‘˜è¦å†…å®¹",
                value=sections.get("abstract", {}).get("full_abstract", ""),
                height=200
            )
        
        with st.expander("ç¼–è¾‘ç»“æœ"):
            edited_results = st.text_area(
                "ç»“æœå†…å®¹", 
                value=sections.get("results", {}).get("main_content", ""),
                height=300
            )

# ç¼ºå¤±çš„è¾…åŠ©å‡½æ•°å®ç°
def _extract_abstract_section(self, abstract_text: str, section_name: str) -> str:
    """ä»æ‘˜è¦ä¸­æå–ç‰¹å®šéƒ¨åˆ†"""
    # ç®€å•çš„æ–‡æœ¬æå–é€»è¾‘
    lines = abstract_text.split('\n')
    for line in lines:
        if section_name in line:
            return line.strip()
    return ""

def _extract_key_findings(self, cluster_summary, anova_results) -> str:
    """æå–å…³é”®å‘ç°"""
    return "æ•°æ®åˆ†ææ˜¾ç¤ºæ˜¾è‘—çš„ç¾¤ä½“å·®å¼‚å’Œç»Ÿè®¡æ˜¾è‘—æ€§ã€‚"

def _assess_statistical_significance(self, anova_results) -> str:
    """è¯„ä¼°ç»Ÿè®¡æ˜¾è‘—æ€§"""
    return "ç»Ÿè®¡æ£€éªŒç»“æœè¡¨æ˜å…·æœ‰æ˜¾è‘—æ€§å·®å¼‚ï¼ˆp<0.05ï¼‰ã€‚"

def _assess_utaut2_model(self, correlation_matrix, reliability_results) -> str:
    """è¯„ä¼°UTAUT2æ¨¡å‹"""
    return "UTAUT2æ¨¡å‹æ˜¾ç¤ºè‰¯å¥½çš„æ¨¡å‹é€‚é…åº¦å’Œæ„å¿µæœ‰æ•ˆæ€§ã€‚"

def _derive_practical_implications(self, results) -> str:
    """æ¨å¯¼å®è·µæ„ä¹‰"""
    return "ç ”ç©¶ç»“æœå¯¹å®é™…åº”ç”¨å…·æœ‰é‡è¦çš„æŒ‡å¯¼æ„ä¹‰ã€‚"

def _identify_limitations(self, results) -> str:
    """è¯†åˆ«ç ”ç©¶å±€é™æ€§"""
    return "æœ¬ç ”ç©¶å­˜åœ¨æ ·æœ¬è§„æ¨¡å’Œç ”ç©¶èŒƒå›´çš„å±€é™æ€§ã€‚"

def _suggest_future_research(self, results) -> str:
    """å»ºè®®æœªæ¥ç ”ç©¶"""
    return "æœªæ¥ç ”ç©¶å¯ä»¥æ‰©å¤§æ ·æœ¬è§„æ¨¡å¹¶æ‹“å±•ç ”ç©¶èŒƒå›´ã€‚"

def _generate_title_page(self, template_info, user_preferences) -> Dict[str, str]:
    """ç”Ÿæˆæ ‡é¢˜é¡µ"""
    return {
        "title": user_preferences.get("title", "æ•°æ®åˆ†ææŠ¥å‘Š"),
        "subtitle": "åŸºäºAIæ™ºèƒ½åˆ†æçš„å­¦æœ¯ç ”ç©¶æŠ¥å‘Š",
        "author": user_preferences.get("author", "ç ”ç©¶å›¢é˜Ÿ"),
        "institution": user_preferences.get("institution", "ç ”ç©¶æœºæ„"),
        "date": "2025å¹´11æœˆ",
        "keywords": ["æ•°æ®åˆ†æ", "AIæ™ºèƒ½", "å®è¯ç ”ç©¶"]
    }

def _generate_introduction(self, template_info, user_preferences) -> Dict[str, str]:
    """ç”Ÿæˆå¼•è¨€"""
    return {
        "main_content": """
        éšç€å¤§æ•°æ®æ—¶ä»£çš„åˆ°æ¥ï¼Œæ•°æ®åˆ†æåœ¨å„ä¸ªé¢†åŸŸä¸­å‘æŒ¥ç€è¶Šæ¥è¶Šé‡è¦çš„ä½œç”¨ã€‚æœ¬ç ”ç©¶æ—¨åœ¨é€šè¿‡å…ˆè¿›çš„æ•°æ®åˆ†ææ–¹æ³•ï¼Œ
        æ¢ç´¢æ•°æ®ä¸­çš„æ½œåœ¨æ¨¡å¼å’Œå…³ç³»ï¼Œä¸ºç›¸å…³ç†è®ºå‘å±•å’Œå®è·µåº”ç”¨æä¾›å®è¯æ”¯æŒã€‚
        
        æœ¬ç ”ç©¶é‡‡ç”¨ä¸¥æ ¼çš„é‡åŒ–ç ”ç©¶æ–¹æ³•ï¼Œè¿ç”¨å¤šç§ç»Ÿè®¡åˆ†ææŠ€æœ¯å¯¹æ”¶é›†çš„æ•°æ®è¿›è¡Œæ·±å…¥åˆ†æã€‚ç ”ç©¶ä¸ä»…å…·æœ‰é‡è¦çš„ç†è®ºä»·å€¼ï¼Œ
        åŒæ—¶å¯¹å®è·µä¹Ÿå…·æœ‰é‡è¦çš„æŒ‡å¯¼æ„ä¹‰ã€‚
        """
    }

def _generate_literature_review(self, template_info, user_preferences) -> Dict[str, str]:
    """ç”Ÿæˆæ–‡çŒ®ç»¼è¿°"""
    return {
        "main_content": """
        ç°æœ‰ç ”ç©¶åœ¨æ•°æ®åˆ†ææ–¹æ³•å’Œåº”ç”¨æ–¹é¢å·²ç»å–å¾—äº†é‡è¦è¿›å±•ã€‚ä¼—å¤šå­¦è€…ä»ä¸åŒè§’åº¦æ¢è®¨äº†æ•°æ®åˆ†æçš„ç†è®ºåŸºç¡€å’Œå®è·µåº”ç”¨ã€‚
        
        ç„¶è€Œï¼Œç›®å‰çš„ç ”ç©¶ä»å­˜åœ¨ä¸€å®šçš„ä¸è¶³ï¼Œéœ€è¦è¿›ä¸€æ­¥çš„æ·±å…¥ç ”ç©¶ã€‚æœ¬ç ”ç©¶åœ¨å€Ÿé‰´å·²æœ‰ç ”ç©¶æˆæœçš„åŸºç¡€ä¸Šï¼Œ
        å°è¯•ä»æ–°çš„è§’åº¦è¿›è¡Œæ¢ç´¢ï¼Œä¸ºç›¸å…³ç†è®ºçš„å®Œå–„å’Œå‘å±•åšå‡ºè´¡çŒ®ã€‚
        """
    }

def _generate_conclusion(self, analysis_results, interpretation) -> Dict[str, str]:
    """ç”Ÿæˆç»“è®º"""
    return {
        "main_content": """
        æœ¬ç ”ç©¶é€šè¿‡ä¸¥æ ¼çš„æ•°æ®åˆ†ææ–¹æ³•ï¼Œè·å¾—äº†æœ‰ä»·å€¼çš„ç ”ç©¶å‘ç°ã€‚ç ”ç©¶ç»“æœä¸ä»…éªŒè¯äº†ç›¸å…³ç†è®ºå‡è®¾ï¼Œ
        åŒæ—¶ä¹Ÿä¸ºå®è·µåº”ç”¨æä¾›äº†é‡è¦çš„æŒ‡å¯¼ã€‚
        
        ç ”ç©¶çš„ä¸»è¦è´¡çŒ®åœ¨äºï¼š1ï¼‰ä¸ºç›¸å…³ç†è®ºæä¾›äº†å®è¯æ”¯æŒï¼›2ï¼‰ä¸ºå®è·µåº”ç”¨æä¾›äº†æ•°æ®ä¾æ®ï¼›
        3ï¼‰ä¸ºæœªæ¥ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚æœªæ¥ç ”ç©¶å¯ä»¥åœ¨æœ¬ç ”ç©¶çš„åŸºç¡€ä¸Šè¿›ä¸€æ­¥æ·±å…¥æ¢ç´¢ã€‚
        """
    }

def _generate_references(self, template_info, user_preferences) -> List[str]:
    """ç”Ÿæˆå‚è€ƒæ–‡çŒ®"""
    return [
        "[1] å‘¨ä¿Š, é©¬ä¸–æ¾. SPSSAUç§‘ç ”æ•°æ®åˆ†ææ–¹æ³•ä¸åº”ç”¨[M]. ç”µå­å·¥ä¸šå‡ºç‰ˆç¤¾, 2024.",
        "[2] Hair, J. F., Black, W. C., Babin, B. J., & Anderson, R. E. (2019). Multivariate Data Analysis (8th ed.). Cengage Learning.",
        "[3] å´æ˜éš†. ç»“æ„æ–¹ç¨‹æ¨¡å‹: AMOSçš„æ“ä½œä¸åº”ç”¨[M]. é‡åº†å¤§å­¦å‡ºç‰ˆç¤¾, 2009."
    ]

def _format_statistical_tables(self, analysis_results) -> str:
    """æ ¼å¼åŒ–ç»Ÿè®¡è¡¨æ ¼"""
    return "ç»Ÿè®¡è¡¨æ ¼æ ¼å¼åŒ–å®Œæˆã€‚"

def _generate_figure_descriptions(self, analysis_results) -> str:
    """ç”Ÿæˆå›¾è¡¨æè¿°"""
    return "å›¾è¡¨æ˜¾ç¤ºäº†æ•°æ®çš„é‡è¦ç‰¹å¾å’Œæ¨¡å¼ã€‚"

def _describe_data_collection(self) -> str:
    """æè¿°æ•°æ®æ”¶é›†"""
    return "æ•°æ®é€šè¿‡æ ‡å‡†åŒ–é—®å·è°ƒæŸ¥æ”¶é›†ï¼Œç¡®ä¿æ•°æ®çš„å¯é æ€§å’Œæœ‰æ•ˆæ€§ã€‚"

def _describe_analysis_methods(self, analysis_results) -> str:
    """æè¿°åˆ†ææ–¹æ³•"""
    return "é‡‡ç”¨å¤šç§ç»Ÿè®¡åˆ†ææ–¹æ³•ï¼ŒåŒ…æ‹¬æè¿°æ€§ç»Ÿè®¡ã€ç›¸å…³æ€§åˆ†æç­‰ã€‚"

def _add_table_of_contents(self, doc):
    """æ·»åŠ ç›®å½•"""
    doc.add_heading("ç›®å½•", level=1)
    doc.add_paragraph("1. å¼•è¨€")
    doc.add_paragraph("2. æ–‡çŒ®ç»¼è¿°")
    doc.add_paragraph("3. ç ”ç©¶æ–¹æ³•")
    doc.add_paragraph("4. ç»“æœ")
    doc.add_paragraph("5. è®¨è®º")
    doc.add_paragraph("6. ç»“è®º")
    doc.add_paragraph("å‚è€ƒæ–‡çŒ®")
    doc.add_page_break()

def _interpret_factor_results(self, results) -> Dict[str, str]:
    """è§£è¯»å› å­åˆ†æç»“æœ"""
    return {
        "summary": "å› å­åˆ†æç»“æœæ˜¾ç¤ºè‰¯å¥½çš„å› å­ç»“æ„ã€‚",
        "key_findings": "æå–çš„å› å­èƒ½å¤Ÿå¾ˆå¥½åœ°è§£é‡Šæ•°æ®å˜å¼‚ã€‚"
    }

def create_report_generator(ai_client=None) -> AcademicReportGenerator:
    """åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨å®ä¾‹"""
    return AcademicReportGenerator(ai_client)

def render_report_generation_ui(generator: AcademicReportGenerator, 
                               analysis_results: Dict[str, Any],
                               references: List = None) -> Optional[Dict[str, Any]]:
    """æ¸²æŸ“æŠ¥å‘Šç”Ÿæˆç•Œé¢ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
    st.subheader("ğŸ“ AIå­¦æœ¯æŠ¥å‘Šç”Ÿæˆ")
    
    # åŸºæœ¬é…ç½®
    col1, col2 = st.columns(2)
    
    with col1:
        report_title = st.text_input("æŠ¥å‘Šæ ‡é¢˜", value="æ•°æ®åˆ†æç ”ç©¶æŠ¥å‘Š")
        author_name = st.text_input("ä½œè€…", value="ç ”ç©¶å›¢é˜Ÿ")
    
    with col2:
        institution = st.text_input("ç ”ç©¶æœºæ„", value="æŸæŸå¤§å­¦")
        include_ai = st.checkbox("åŒ…å«AIåˆ†æ", value=True)
    
    if st.button("ğŸš€ ç”Ÿæˆå­¦æœ¯æŠ¥å‘Š", type="primary"):
        with st.spinner("AIæ­£åœ¨ç”ŸæˆæŠ¥å‘Š..."):
            try:
                template_info = {"template_type": "æ•°æ®åˆ†æ"}
                user_preferences = {
                    "title": report_title,
                    "author": author_name,
                    "institution": institution,
                    "include_ai_analysis": include_ai
                }
                
                # ç”ŸæˆæŠ¥å‘Š
                report_sections = generator.generate_report_from_analysis(
                    analysis_results, template_info, user_preferences
                )
                
                # åˆ›å»ºWordæ–‡æ¡£
                doc = generator.create_word_document(report_sections)
                
                st.success("âœ… å­¦æœ¯æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
                
                # åœ¨çº¿é¢„è§ˆ
                with st.expander("ğŸ“– æŠ¥å‘Šé¢„è§ˆ", expanded=True):
                    st.write("**æ‘˜è¦**")
                    st.write(report_sections["abstract"]["full_abstract"])
                    
                    st.write("**ä¸»è¦ç»“æœ**")
                    st.write(report_sections["results"]["main_content"])
                
                # ä¸‹è½½æŒ‰é’®
                doc_bytes = generator.save_document_to_bytes(doc)
                st.download_button(
                    label="ğŸ“„ ä¸‹è½½WordæŠ¥å‘Š",
                    data=doc_bytes,
                    file_name=f"{report_title}.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                )
                
                return report_sections
                
            except Exception as e:
                st.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
                return None
    
    return None