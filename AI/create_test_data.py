import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# è®¾ç½®éšæœºç§å­ç¡®ä¿ç»“æœå¯é‡ç°
np.random.seed(42)

# åˆ›å»ºæµ‹è¯•æ•°æ®é›†
n_samples = 500

# ç”ŸæˆåŸºç¡€æ•°æ®
data = {
    # äººå£ç»Ÿè®¡å­¦å˜é‡
    'ID': range(1, n_samples + 1),
    'æ€§åˆ«': np.random.choice(['ç”·', 'å¥³'], n_samples, p=[0.45, 0.55]),
    'å¹´é¾„': np.random.normal(35, 12, n_samples).astype(int),
    'æ•™è‚²æ°´å¹³': np.random.choice(['é«˜ä¸­ä»¥ä¸‹', 'é«˜ä¸­', 'å¤§ä¸“', 'æœ¬ç§‘', 'ç ”ç©¶ç”Ÿ'], 
                                n_samples, p=[0.15, 0.25, 0.25, 0.25, 0.1]),
    'æ”¶å…¥æ°´å¹³': np.random.choice(['ä½', 'ä¸­', 'é«˜'], n_samples, p=[0.3, 0.5, 0.2]),
    
    # å¿ƒç†é‡è¡¨æ•°æ® (Likert 1-5)
    'ç”Ÿæ´»æ»¡æ„åº¦1': np.random.choice([1, 2, 3, 4, 5], n_samples, p=[0.05, 0.15, 0.35, 0.35, 0.1]),
    'ç”Ÿæ´»æ»¡æ„åº¦2': np.random.choice([1, 2, 3, 4, 5], n_samples, p=[0.05, 0.15, 0.35, 0.35, 0.1]),
    'ç”Ÿæ´»æ»¡æ„åº¦3': np.random.choice([1, 2, 3, 4, 5], n_samples, p=[0.05, 0.15, 0.35, 0.35, 0.1]),
    'å·¥ä½œæ»¡æ„åº¦1': np.random.choice([1, 2, 3, 4, 5], n_samples, p=[0.1, 0.2, 0.3, 0.3, 0.1]),
    'å·¥ä½œæ»¡æ„åº¦2': np.random.choice([1, 2, 3, 4, 5], n_samples, p=[0.1, 0.2, 0.3, 0.3, 0.1]),
    'å·¥ä½œæ»¡æ„åº¦3': np.random.choice([1, 2, 3, 4, 5], n_samples, p=[0.1, 0.2, 0.3, 0.3, 0.1]),
    
    # åå‘é¢˜ï¼ˆæ•…æ„è®¾è®¡ä¸å…¶ä»–é¢˜ç›®è´Ÿç›¸å…³ï¼‰
    'å‹åŠ›æ°´å¹³1': 6 - np.random.choice([1, 2, 3, 4, 5], n_samples, p=[0.1, 0.2, 0.4, 0.2, 0.1]),
    'ç„¦è™‘æ°´å¹³1': 6 - np.random.choice([1, 2, 3, 4, 5], n_samples, p=[0.1, 0.2, 0.4, 0.2, 0.1]),
    
    # å¤šé€‰é¢˜æ•°æ® (0/1ç¼–ç )
    'å…´è¶£çˆ±å¥½_è¿åŠ¨': np.random.choice([0, 1], n_samples, p=[0.4, 0.6]),
    'å…´è¶£çˆ±å¥½_é˜…è¯»': np.random.choice([0, 1], n_samples, p=[0.5, 0.5]),
    'å…´è¶£çˆ±å¥½_éŸ³ä¹': np.random.choice([0, 1], n_samples, p=[0.3, 0.7]),
    'å…´è¶£çˆ±å¥½_æ—…æ¸¸': np.random.choice([0, 1], n_samples, p=[0.6, 0.4]),
    'å…´è¶£çˆ±å¥½_ç¾é£Ÿ': np.random.choice([0, 1], n_samples, p=[0.2, 0.8]),
    
    # è¿ç»­å˜é‡
    'èº«é«˜': np.random.normal(165, 10, n_samples),
    'ä½“é‡': np.random.normal(65, 15, n_samples),
    'æœˆæ”¶å…¥': np.random.exponential(5000, n_samples) + 3000,
    
    # æ—¶é—´åºåˆ—æ•°æ®
    'æµ‹é‡æ—¶é—´': [datetime(2023, 1, 1) + timedelta(days=i) for i in range(n_samples)],
    
    # åˆ†ç»„å˜é‡ï¼ˆç”¨äºtæ£€éªŒå’Œæ–¹å·®åˆ†æï¼‰
    'å®éªŒç»„': np.random.choice(['å¯¹ç…§ç»„', 'å®éªŒç»„'], n_samples, p=[0.5, 0.5]),
    'åœ°åŒº': np.random.choice(['åŒ—æ–¹', 'å—æ–¹', 'ä¸œéƒ¨', 'è¥¿éƒ¨'], n_samples, p=[0.25, 0.25, 0.25, 0.25]),
    
    # äºŒåˆ†ç±»ç»“æœå˜é‡ï¼ˆç”¨äºé€»è¾‘å›å½’ï¼‰
    'æ˜¯å¦æ»¡æ„': np.random.choice(['æ˜¯', 'å¦'], n_samples, p=[0.7, 0.3]),
}

# åˆ›å»ºDataFrame
df = pd.DataFrame(data)

# æ·»åŠ ä¸€äº›ç›¸å…³æ€§
# è®©ç”Ÿæ´»æ»¡æ„åº¦å„é¢˜ç›®ç›¸å…³
life_base = np.random.normal(3, 1, n_samples)
df['ç”Ÿæ´»æ»¡æ„åº¦1'] = np.clip(life_base + np.random.normal(0, 0.3, n_samples), 1, 5).astype(int)
df['ç”Ÿæ´»æ»¡æ„åº¦2'] = np.clip(life_base + np.random.normal(0, 0.3, n_samples), 1, 5).astype(int)
df['ç”Ÿæ´»æ»¡æ„åº¦3'] = np.clip(life_base + np.random.normal(0, 0.3, n_samples), 1, 5).astype(int)

# è®©å·¥ä½œæ»¡æ„åº¦ç›¸å…³
work_base = np.random.normal(3, 1, n_samples)
df['å·¥ä½œæ»¡æ„åº¦1'] = np.clip(work_base + np.random.normal(0, 0.3, n_samples), 1, 5).astype(int)
df['å·¥ä½œæ»¡æ„åº¦2'] = np.clip(work_base + np.random.normal(0, 0.3, n_samples), 1, 5).astype(int)
df['å·¥ä½œæ»¡æ„åº¦3'] = np.clip(work_base + np.random.normal(0, 0.3, n_samples), 1, 5).astype(int)

# BMIè®¡ç®—
df['BMI'] = df['ä½“é‡'] / (df['èº«é«˜'] / 100) ** 2

# æ·»åŠ ä¸€äº›ç¼ºå¤±å€¼
missing_indices = np.random.choice(df.index, size=int(0.05 * len(df)), replace=False)
df.loc[missing_indices, 'æœˆæ”¶å…¥'] = np.nan

missing_indices = np.random.choice(df.index, size=int(0.03 * len(df)), replace=False)
df.loc[missing_indices, 'ç”Ÿæ´»æ»¡æ„åº¦3'] = np.nan

# æ·»åŠ å¼‚å¸¸å€¼
outlier_indices = np.random.choice(df.index, size=int(0.02 * len(df)), replace=False)
df.loc[outlier_indices, 'æœˆæ”¶å…¥'] = df.loc[outlier_indices, 'æœˆæ”¶å…¥'] * 10

# ä¿å­˜æ•°æ®
df.to_csv('/workspaces/ningmeng/AI/comprehensive_test_data.csv', index=False, encoding='utf-8')

print("âœ… ç»¼åˆæµ‹è¯•æ•°æ®é›†å·²åˆ›å»º")
print(f"ğŸ“Š æ•°æ®å½¢çŠ¶: {df.shape}")
print(f"ğŸ“‹ å˜é‡ç±»å‹:")
print(f"   - åˆ†ç±»å˜é‡: {len(df.select_dtypes(include=['object']).columns)} ä¸ª")
print(f"   - æ•°å€¼å˜é‡: {len(df.select_dtypes(include=['number']).columns)} ä¸ª")
print(f"   - æ—¶é—´å˜é‡: {len(df.select_dtypes(include=['datetime']).columns)} ä¸ª")
print(f"ğŸ” æ•°æ®è´¨é‡:")
print(f"   - ç¼ºå¤±å€¼: {df.isnull().sum().sum()} ä¸ª")
print(f"   - é‡å¤è¡Œ: {df.duplicated().sum()} ä¸ª")
print("\nğŸ“ æ•°æ®è¯´æ˜:")
print("- åŒ…å«å¿ƒç†é‡è¡¨é¢˜ç›®ï¼ˆç”¨äºä¿¡åº¦æ•ˆåº¦åˆ†æï¼‰")
print("- åŒ…å«å¤šé€‰é¢˜æ•°æ®ï¼ˆç”¨äºå¤šé€‰é¢˜åˆ†æï¼‰")
print("- åŒ…å«åˆ†ç»„å˜é‡ï¼ˆç”¨äºtæ£€éªŒå’Œæ–¹å·®åˆ†æï¼‰")
print("- åŒ…å«è¿ç»­å˜é‡ï¼ˆç”¨äºç›¸å…³åˆ†æå’Œå›å½’ï¼‰")
print("- åŒ…å«æ—¶é—´åºåˆ—æ•°æ®ï¼ˆç”¨äºè¶‹åŠ¿åˆ†æï¼‰")
print("- åŒ…å«ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼ï¼ˆç”¨äºæ•°æ®è´¨é‡è¯„ä¼°ï¼‰")