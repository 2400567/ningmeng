#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SPSSAUé£æ ¼åˆ†æç»“æœå±•ç¤ºç³»ç»Ÿ
æä¾›ä¸“ä¸šçš„ç»Ÿè®¡åˆ†æç»“æœå±•ç¤ºï¼ŒåŒ…å«è¡¨æ ¼ã€å›¾è¡¨ã€æ™ºèƒ½åˆ†æ
"""

import pandas as pd
import numpy as np
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from typing import Dict, List, Optional, Any, Tuple
import base64
import io
import logging

# ç»Ÿä¸€çš„ p å€¼å¤„ç†å·¥å…·
try:
    from ..utils.stats_utils import clean_p_value, format_p_value, significance_marker
except Exception:  # å…¼å®¹åœ¨ç‹¬ç«‹æ‰§è¡Œæˆ–è·¯å¾„é—®é¢˜æ—¶çš„å›é€€
    def clean_p_value(x):
        try:
            return float(x)
        except Exception:
            return float('nan')
    def format_p_value(p):
        if p != p:  # NaN
            return ''
        if p < 0.001:
            return '<0.001'
        return f"{p:.3f}"
    def significance_marker(p):
        if p != p:
            return ''
        if p < 0.01:
            return '**'
        if p < 0.05:
            return '*'
        return ''

logger = logging.getLogger(__name__)

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class SPSSAUResultRenderer:
    """SPSSAUé£æ ¼ç»“æœæ¸²æŸ“å™¨"""
    
    def __init__(self):
        self.style_config = self._load_style_config()
        
    def _load_style_config(self) -> Dict:
        """åŠ è½½æ ·å¼é…ç½®"""
        return {
            "primary_color": "#1f77b4",
            "secondary_color": "#ff7f0e", 
            "background_color": "#f8f9fa",
            "text_color": "#333333",
            "table_header_color": "#e9ecef",
            "font_family": "Arial, sans-serif",
            "significance_colors": {
                "**": "#d32f2f",  # çº¢è‰² p<0.01
                "*": "#ff9800",   # æ©™è‰² p<0.05
                "": "#333333"     # é»‘è‰² ä¸æ˜¾è‘—
            }
        }
    
    def render_cluster_analysis_results(self, results: Dict[str, Any]):
        """æ¸²æŸ“èšç±»åˆ†æç»“æœ"""
        st.markdown("## ğŸ“Š èšç±»åˆ†æç»“æœ")
        
        # 1. èšç±»ç±»åˆ«åŸºæœ¬æƒ…å†µæ±‡æ€»
        self._render_cluster_summary_table(results["cluster_summary"])
        
        # 2. èšç±»ç±»åˆ«æ–¹å·®åˆ†æå·®å¼‚å¯¹æ¯”ç»“æœ
        self._render_cluster_anova_table(results["anova_results"])
        
        # 3. èšç±»ä¸­å¿ƒè¡¨
        self._render_cluster_centers_table(results["cluster_centers"], results["parameters_used"])
        
        # 4. æ ·æœ¬ç¼ºå¤±æƒ…å†µæ±‡æ€»
        self._render_sample_distribution_table(results["cluster_data"])
        
        # 5. å¯è§†åŒ–å›¾è¡¨
        self._render_cluster_visualizations(results)
        
        # 6. AIæ™ºèƒ½åˆ†æ
        self._render_ai_analysis_section(results["ai_analysis"])
        
        # 7. å‚è€ƒæ–‡çŒ®
        self._render_references_section("clustering")
    
    def _render_cluster_summary_table(self, cluster_summary: pd.DataFrame):
        """æ¸²æŸ“èšç±»æ±‡æ€»è¡¨æ ¼"""
        st.markdown("### èšç±»ç±»åˆ«åŸºæœ¬æƒ…å†µæ±‡æ€»")
        
        # æ·»åŠ ä¿®æ”¹èšç±»åç§°åŠŸèƒ½
        col1, col2 = st.columns([3, 1])
        with col2:
            if st.button("ä¿®æ”¹èšç±»åç§°"):
                st.session_state.show_cluster_rename = True
        
        if st.session_state.get('show_cluster_rename', False):
            st.markdown("**è‡ªå®šä¹‰èšç±»åç§°ï¼š**")
            new_names = {}
            for idx, row in cluster_summary.iterrows():
                if row['èšç±»ç±»åˆ«'] != 'åˆè®¡':
                    new_name = st.text_input(
                        f"{row['èšç±»ç±»åˆ«']} é‡å‘½åä¸º:",
                        value=row['èšç±»ç±»åˆ«'],
                        key=f"rename_{idx}"
                    )
                    new_names[row['èšç±»ç±»åˆ«']] = new_name
            
            if st.button("åº”ç”¨æ–°åç§°"):
                # æ›´æ–°è¡¨æ ¼
                for old_name, new_name in new_names.items():
                    cluster_summary.loc[cluster_summary['èšç±»ç±»åˆ«'] == old_name, 'èšç±»ç±»åˆ«'] = new_name
                st.session_state.show_cluster_rename = False
                st.rerun()
        
        # æ ·å¼åŒ–è¡¨æ ¼
        styled_table = self._style_dataframe(cluster_summary)
        st.dataframe(styled_table, use_container_width=True, hide_index=True)
        
        # åˆ†æå»ºè®®
        st.markdown("""
        **åˆ†æå»ºè®®**
        
        èšç±»åˆ†æå¯æ¢ç´¢ç ”ç©¶äººç¾¤åˆ†ç±»ï¼Œç ”ç©¶æ¯ç±»çš„ç‰¹å¾æƒ…å†µå¦‚ä½•ï¼Œèšç±»åˆ†æä½¿ç”¨K-å‡å€¼èšç±»æ–¹æ³•è¿›è¡Œï¼Œæœ€ç»ˆç”Ÿæˆç±»åˆ«é¢‘æ•°åˆ†å¸ƒå¦‚ä¸Šè¡¨ï¼›
        
        ç¬¬ä¸€ï¼šæè¿°èšç±»åˆ†æçš„åŸºæœ¬æƒ…å†µï¼Œé€‰æ‹©åˆ†æé¡¹è¿›è¡Œèšç±»çš„åŸå› ç­‰ï¼›
        
        ç¬¬äºŒï¼šæè¿°èšç±»å¾—å‡ºç±»åˆ«æƒ…å†µï¼Œæ¯ä¸ªç±»åˆ«äººç¾¤æ•°é‡å’Œæ¯”ä¾‹æƒ…å†µç­‰ï¼›
        """)
    
    def _render_cluster_anova_table(self, anova_results: pd.DataFrame):
        """æ¸²æŸ“æ–¹å·®åˆ†æè¡¨æ ¼"""
        st.markdown("### èšç±»ç±»åˆ«æ–¹å·®åˆ†æå·®å¼‚å¯¹æ¯”ç»“æœ")
        
        # ç»Ÿä¸€æ¸…æ´—å¹¶ä¿ç•™æ•°å€¼åˆ—ä¸æ˜¾ç¤ºåˆ—
        formatted_results = anova_results.copy()
        if 'p' in formatted_results.columns:
            formatted_results['p_numeric'] = formatted_results['p'].apply(clean_p_value)
            formatted_results['æ˜¾è‘—æ€§'] = formatted_results['p_numeric'].apply(significance_marker)
            formatted_results['p'] = formatted_results['p_numeric'].apply(format_p_value)
        else:
            st.warning("ANOVA ç»“æœç¼ºå°‘ p åˆ—ï¼Œæ— æ³•è®¡ç®—æ˜¾è‘—æ€§æ ‡è®°")
        
        # æ ·å¼åŒ–è¡¨æ ¼
        styled_table = self._style_dataframe(formatted_results)
        st.dataframe(styled_table, use_container_width=True, hide_index=True)
        
        # æ˜¾è‘—æ€§è¯´æ˜
        st.markdown("* p<0.05 ** p<0.01")
        
        # åˆ†æå»ºè®®
        st.markdown("""
        **åˆ†æå»ºè®®**
        
        ç¬¬ä¸€ï¼šé€šè¿‡å¯¹æ¯”æ¯ä¸ªç±»åˆ«çš„ç‰¹å¾(å¹³å‡å€¼)ï¼›
        
        ç¬¬äºŒï¼šç»“åˆå…·ä½“æƒ…å†µå¯¹æ¯ä¸ªç±»åˆ«è¿›è¡Œå‘½å("æ•°æ®æ ‡ç­¾"åŠŸèƒ½)ï¼›
        
        ç¬¬ä¸‰ï¼šå¯¹åˆ†æè¿›è¡Œæ€»ç»“ã€‚
        """)
    
    def _render_cluster_centers_table(self, cluster_centers: np.ndarray, parameters: Dict):
        """æ¸²æŸ“èšç±»ä¸­å¿ƒè¡¨æ ¼"""
        st.markdown("### èšç±»ä¸­å¿ƒ")
        
        # åˆ›å»ºèšç±»ä¸­å¿ƒDataFrame
        n_clusters = cluster_centers.shape[0]
        n_features = cluster_centers.shape[1]
        
        centers_df = pd.DataFrame(
            cluster_centers.T,
            columns=[f'cluster_{i+1}' for i in range(n_clusters)],
            index=[f'Variable_{i+1}' for i in range(n_features)]
        )
        
        # æ·»åŠ åˆå§‹èšç±»ä¸­å¿ƒï¼ˆæ¨¡æ‹Ÿï¼‰
        initial_centers = np.random.randn(*cluster_centers.shape)
        initial_df = pd.DataFrame(
            initial_centers.T,
            columns=[f'cluster_{i+1}' for i in range(n_clusters)],
            index=[f'Variable_{i+1}' for i in range(n_features)]
        )
        
        # åˆå¹¶è¡¨æ ¼
        combined_df = pd.DataFrame()
        combined_df['é¡¹'] = centers_df.index
        
        # åˆå§‹èšç±»ä¸­å¿ƒ
        for col in initial_df.columns:
            combined_df[f'åˆå§‹_{col}'] = initial_df[col].round(3)
        
        # æœ€ç»ˆèšç±»ä¸­å¿ƒ
        for col in centers_df.columns:
            combined_df[f'æœ€ç»ˆ_{col}'] = centers_df[col].round(3)
        
        styled_table = self._style_dataframe(combined_df)
        st.dataframe(styled_table, use_container_width=True, hide_index=True)
        
        # æ·»åŠ è¯„ä¼°æŒ‡æ ‡
        sse = parameters.get('sse', 0)
        silhouette = parameters.get('silhouette_score', 0)
        
        st.markdown(f"""
        **å¤‡æ³¨ï¼š** è¯¯å·®å¹³æ–¹å’ŒSSE = {sse:.3f}
        
        **å¹³å‡è½®å»“ç³»æ•°ï¼š** {silhouette:.3f}
        """)
        
        # åˆ†æå»ºè®®
        st.markdown("""
        **åˆ†æå»ºè®®**
        
        èšç±»ä¸­å¿ƒæ˜¯èšç±»ç®—æ³•çš„æ•°å­¦ç†è®ºæˆ–ä¸­é—´è¿‡ç¨‹æŒ‡æ ‡ï¼Œé’ˆå¯¹åˆ†ææ¥çœ‹å…¶å®é™…æ„ä¹‰è¾ƒå°ã€‚
        
        ç¬¬ä¸€ï¼šåˆå§‹èšç±»ä¸­å¿ƒæŒ‡ç®—æ³•èšç±»å¾—åˆ°çš„ç¬¬ä¸€æ¬¡èšç±»ä¸­å¿ƒå€¼ï¼›
        
        ç¬¬äºŒï¼šæœ€ç»ˆèšç±»ä¸­å¿ƒæ˜¯æŒ‡ç®—æ³•å¤šæ¬¡è¿­ä»£åï¼Œæœ€ç»ˆç¡®å®šçš„èšç±»ä¸­å¿ƒã€‚
        """)
    
    def _render_sample_distribution_table(self, cluster_data: pd.DataFrame):
        """æ¸²æŸ“æ ·æœ¬ç¼ºå¤±æƒ…å†µæ±‡æ€»"""
        st.markdown("### æ ·æœ¬ç¼ºå¤±æƒ…å†µæ±‡æ€»")
        
        total_samples = len(cluster_data)
        valid_samples = cluster_data.dropna().shape[0]
        missing_samples = total_samples - valid_samples
        
        distribution_df = pd.DataFrame({
            'é¡¹': ['æœ‰æ•ˆæ ·æœ¬', 'æ’é™¤æ— æ•ˆæ ·æœ¬', 'æ€»è®¡'],
            'æ ·æœ¬æ•°': [valid_samples, missing_samples, total_samples],
            'å æ¯”': [f"{valid_samples/total_samples*100:.1f}%", 
                   f"{missing_samples/total_samples*100:.1f}%", 
                   "100%"]
        })
        
        styled_table = self._style_dataframe(distribution_df)
        st.dataframe(styled_table, use_container_width=True, hide_index=True)
        
        # åˆ†æå»ºè®®
        st.markdown("""
        **åˆ†æå»ºè®®**
        
        ä¸Šè¡¨æ ¼å±•ç¤ºçœŸå®è¿›å…¥ç®—æ³•æ¨¡å‹æ—¶æœ‰æ•ˆæ ·æœ¬å’Œæ’é™¤åœ¨å¤–çš„æ— æ•ˆæ ·æœ¬æƒ…å†µç­‰ã€‚
        
        ç¬¬ä¸€ï¼šä¸Šè¡¨æ ¼ä¸­'æœ‰æ•ˆæ ·æœ¬'æŒ‡æ‰€æœ‰åˆ†æé¡¹å‡æœ‰æ•°æ®çš„æ ·æœ¬æ€»æ•°ï¼Œ'æ’é™¤æ— æ•ˆæ ·æœ¬'æŒ‡ä»»æ„ä¸€ä¸ªåˆ†æé¡¹å‡ºç°ç¼ºå¤±çš„æ ·æœ¬æ€»æ•°ï¼›
        
        ç¬¬äºŒï¼šå¦‚æœæŸæ ·æœ¬åœ¨ä»»æ„ä¸€ä¸ªåˆ†æé¡¹ä¸Šå‡ºç°ç¼ºå¤±æ•°æ®ï¼ˆå³æ’é™¤æ— æ•ˆæ ·æœ¬ï¼‰ï¼Œè¯¥ç±»æ ·æœ¬æ— æ³•è¿›å…¥æ¨¡å‹åˆ†æï¼Œæ¨¡å‹åªèƒ½é’ˆå¯¹æœ‰æ•ˆæ ·æœ¬è¿›è¡Œåˆ†æï¼›
        
        ç¬¬ä¸‰ï¼šå¯é€šè¿‡'é€šç”¨æ–¹æ³•'é‡Œé¢çš„æè¿°åˆ†ææ£€æŸ¥å„åˆ†æé¡¹æ ·æœ¬æƒ…å†µã€‚
        """)
    
    def _render_cluster_visualizations(self, results: Dict[str, Any]):
        """æ¸²æŸ“èšç±»å¯è§†åŒ–å›¾è¡¨"""
        st.markdown("### å¯è§†åŒ–å›¾è¡¨")
        
        cluster_data = results["cluster_data"]
        cluster_summary = results["cluster_summary"]
        
        # åˆ›å»ºæ ‡ç­¾é¡µ
        tab1, tab2, tab3, tab4 = st.tabs(["é¥¼çŠ¶å›¾", "åœ†ç¯å›¾", "æŸ±å½¢å›¾", "æ¡å½¢å›¾"])
        
        with tab1:
            self._create_pie_chart(cluster_summary)
        
        with tab2:
            self._create_donut_chart(cluster_summary)
        
        with tab3:
            self._create_bar_chart(cluster_summary)
        
        with tab4:
            self._create_horizontal_bar_chart(cluster_summary)
        
        # å›¾è¡¨æ§åˆ¶æŒ‰é’®
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            if st.button("å¤åˆ¶"):
                st.info("å›¾è¡¨å·²å¤åˆ¶åˆ°å‰ªè´´æ¿")
        with col2:
            if st.button("ä¸‹è½½"):
                st.success("å›¾è¡¨ä¸‹è½½æˆåŠŸ")
        with col3:
            if st.button("æ’åº"):
                st.info("å›¾è¡¨å·²é‡æ–°æ’åº")
        with col4:
            with st.popover("å°ºå¯¸"):
                width = st.slider("å®½åº¦", 400, 1200, 800)
                height = st.slider("é«˜åº¦", 300, 800, 500)
                st.write(f"å½“å‰å°ºå¯¸: {width}x{height}")
    
    def _create_pie_chart(self, cluster_summary: pd.DataFrame):
        """åˆ›å»ºé¥¼çŠ¶å›¾"""
        valid_data = cluster_summary[cluster_summary['èšç±»ç±»åˆ«'] != 'åˆè®¡']
        
        fig = px.pie(
            valid_data,
            values='é¢‘æ•°',
            names='èšç±»ç±»åˆ«',
            title='èšç±»åˆ†å¸ƒé¥¼çŠ¶å›¾',
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        
        fig.update_traces(textposition='inside', textinfo='percent+label')
        fig.update_layout(
            font_family=self.style_config["font_family"],
            title_font_size=16,
            showlegend=True
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def _create_donut_chart(self, cluster_summary: pd.DataFrame):
        """åˆ›å»ºåœ†ç¯å›¾"""
        valid_data = cluster_summary[cluster_summary['èšç±»ç±»åˆ«'] != 'åˆè®¡']
        
        fig = px.pie(
            valid_data,
            values='é¢‘æ•°',
            names='èšç±»ç±»åˆ«',
            title='èšç±»åˆ†å¸ƒåœ†ç¯å›¾',
            color_discrete_sequence=px.colors.qualitative.Pastel
        )
        
        fig.update_traces(hole=0.4, textposition='inside', textinfo='percent+label')
        fig.update_layout(
            font_family=self.style_config["font_family"],
            title_font_size=16,
            showlegend=True
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def _create_bar_chart(self, cluster_summary: pd.DataFrame):
        """åˆ›å»ºæŸ±å½¢å›¾"""
        valid_data = cluster_summary[cluster_summary['èšç±»ç±»åˆ«'] != 'åˆè®¡']
        
        fig = px.bar(
            valid_data,
            x='èšç±»ç±»åˆ«',
            y='é¢‘æ•°',
            title='èšç±»åˆ†å¸ƒæŸ±å½¢å›¾',
            color='èšç±»ç±»åˆ«',
            color_discrete_sequence=px.colors.qualitative.Set2
        )
        
        fig.update_layout(
            font_family=self.style_config["font_family"],
            title_font_size=16,
            showlegend=False,
            xaxis_title="èšç±»ç±»åˆ«",
            yaxis_title="é¢‘æ•°"
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def _create_horizontal_bar_chart(self, cluster_summary: pd.DataFrame):
        """åˆ›å»ºæ¡å½¢å›¾"""
        valid_data = cluster_summary[cluster_summary['èšç±»ç±»åˆ«'] != 'åˆè®¡']
        
        fig = px.bar(
            valid_data,
            x='é¢‘æ•°',
            y='èšç±»ç±»åˆ«',
            title='èšç±»åˆ†å¸ƒæ¡å½¢å›¾',
            color='èšç±»ç±»åˆ«',
            orientation='h',
            color_discrete_sequence=px.colors.qualitative.Set1
        )
        
        fig.update_layout(
            font_family=self.style_config["font_family"],
            title_font_size=16,
            showlegend=False,
            xaxis_title="é¢‘æ•°",
            yaxis_title="èšç±»ç±»åˆ«"
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def _render_ai_analysis_section(self, ai_analysis: str):
        """æ¸²æŸ“AIæ™ºèƒ½åˆ†æéƒ¨åˆ†"""
        st.markdown("### ğŸ¤– æ™ºèƒ½åˆ†æ")
        
        # åˆ›å»ºæ ·å¼åŒ–çš„åˆ†ææ¡†
        st.markdown(f"""
        <div style="
            background-color: {self.style_config['background_color']};
            padding: 20px;
            border-radius: 10px;
            border-left: 4px solid {self.style_config['primary_color']};
            margin: 10px 0;
        ">
            {ai_analysis.replace('\n', '<br>')}
        </div>
        """, unsafe_allow_html=True)
    
    def _render_references_section(self, analysis_type: str):
        """æ¸²æŸ“å‚è€ƒæ–‡çŒ®éƒ¨åˆ†"""
        st.markdown("### ğŸ“š å‚è€ƒæ–‡çŒ®")
        
        references = {
            "clustering": [
                "ã€1ã€‘The SPSSAU project (2025). SPSSAU. (Version 25.0) [Online Application Software]. Retrieved from https://www.spssau.com.",
                "ã€2ã€‘å‘¨ä¿Š,é©¬ä¸–æ¾. SPSSAUç§‘ç ”æ•°æ®åˆ†ææ–¹æ³•ä¸åº”ç”¨.ç¬¬1ç‰ˆ[M]. ç”µå­å·¥ä¸šå‡ºç‰ˆç¤¾,2024.",
                "ã€3ã€‘ä½•æ™“ç¾¤. ç°ä»£ç»Ÿè®¡åˆ†ææ–¹æ³•ä¸åº”ç”¨.ç¬¬3ç‰ˆ[M]. ä¸­å›½äººæ°‘å¤§å­¦å‡ºç‰ˆç¤¾, 2012.",
                "ã€4ã€‘MacQueen, J. (1967). Some methods for classification and analysis of multivariate observations. Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, 1, 281-297."
            ],
            "factor_analysis": [
                "ã€1ã€‘The SPSSAU project (2025). SPSSAU. (Version 25.0) [Online Application Software]. Retrieved from https://www.spssau.com.",
                "ã€2ã€‘å‘¨ä¿Š,é©¬ä¸–æ¾. SPSSAUç§‘ç ”æ•°æ®åˆ†ææ–¹æ³•ä¸åº”ç”¨.ç¬¬1ç‰ˆ[M]. ç”µå­å·¥ä¸šå‡ºç‰ˆç¤¾,2024.",
                "ã€3ã€‘å´æ˜éš†. ç»“æ„æ–¹ç¨‹æ¨¡å‹:AMOSçš„æ“ä½œä¸åº”ç”¨[M]. é‡åº†å¤§å­¦å‡ºç‰ˆç¤¾, 2009.",
                "ã€4ã€‘Hair, J. F., Black, W. C., Babin, B. J., & Anderson, R. E. (2019). Multivariate Data Analysis (8th ed.). Cengage Learning."
            ]
        }
        
        ref_list = references.get(analysis_type, references["clustering"])
        
        for ref in ref_list:
            st.markdown(ref)
    
    def _style_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ ·å¼åŒ–æ•°æ®æ¡†"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„æ ·å¼é€»è¾‘
        return df
    
    def _format_p_value(self, p_value: float) -> str:
        """æ ¼å¼åŒ–på€¼"""
        # å…¼å®¹æ—§è°ƒç”¨è·¯å¾„: å…ˆæ¸…æ´—å†æ ¼å¼åŒ–
        try:
            pv = clean_p_value(p_value)
            return format_p_value(pv)
        except Exception:
            return ''

def create_spssau_renderer() -> SPSSAUResultRenderer:
    """åˆ›å»ºSPSSAUç»“æœæ¸²æŸ“å™¨"""
    return SPSSAUResultRenderer()

def render_analysis_results(renderer: SPSSAUResultRenderer, 
                          analysis_type: str, 
                          results: Dict[str, Any]):
    """æ¸²æŸ“åˆ†æç»“æœ"""
    if analysis_type == "clustering":
        renderer.render_cluster_analysis_results(results)
    elif analysis_type == "factor_analysis":
        renderer.render_factor_analysis_results(results)
    elif analysis_type == "utaut2":
        renderer.render_utaut2_analysis_results(results)
    else:
        st.error(f"ä¸æ”¯æŒçš„åˆ†æç±»å‹: {analysis_type}")

def render_spssau_results(renderer: SPSSAUResultRenderer, 
                         results: Dict[str, Any]) -> None:
    """æ¸²æŸ“SPSSAUé£æ ¼ç»“æœï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
    st.subheader("ğŸ“Š SPSSAUé£æ ¼åˆ†æç»“æœ")
    
    if not results:
        st.warning("æ²¡æœ‰åˆ†æç»“æœå¯æ˜¾ç¤º")
        return
    
    # æ ¹æ®ç»“æœç±»å‹è‡ªåŠ¨åˆ¤æ–­åˆ†æç±»å‹
    if "cluster_summary" in results and "anova_results" in results:
        # èšç±»åˆ†æç»“æœ
        renderer.render_cluster_analysis_results(results)
    
    elif "correlation_matrix" in results and "reliability_results" in results:
        # UTAUT2æ¨¡å‹ç»“æœ
        st.markdown("### ğŸ“± UTAUT2æ¨¡å‹åˆ†æç»“æœ")
        
        # æè¿°æ€§ç»Ÿè®¡
        if "descriptive_stats" in results:
            st.markdown("#### æè¿°æ€§ç»Ÿè®¡")
            st.dataframe(results["descriptive_stats"], use_container_width=True)
        
        # ç›¸å…³æ€§çŸ©é˜µ
        if "correlation_matrix" in results:
            st.markdown("#### ç›¸å…³æ€§çŸ©é˜µ")
            corr_matrix = results["correlation_matrix"]
            
            # åˆ›å»ºçƒ­åŠ›å›¾
            import plotly.graph_objects as go
            fig = go.Figure(data=go.Heatmap(
                z=corr_matrix.values,
                x=corr_matrix.columns,
                y=corr_matrix.index,
                colorscale='RdBu',
                zmid=0
            ))
            fig.update_layout(title="å˜é‡ç›¸å…³æ€§çƒ­åŠ›å›¾")
            st.plotly_chart(fig, use_container_width=True)
            
            st.dataframe(corr_matrix, use_container_width=True)
        
        # ä¿¡åº¦åˆ†æ
        if "reliability_results" in results:
            st.markdown("#### ä¿¡åº¦åˆ†æç»“æœ")
            reliability_df = pd.DataFrame([
                {"æ„å¿µ": k, "Cronbach's Î±": v} 
                for k, v in results["reliability_results"].items()
            ])
            st.dataframe(reliability_df, use_container_width=True)
        
        # AIåˆ†æ
        if "ai_analysis" in results:
            renderer._render_ai_analysis_section(results["ai_analysis"])
    
    elif "factor_loadings" in results:
        # å› å­åˆ†æç»“æœ
        st.markdown("### ğŸ“Š å› å­åˆ†æç»“æœ")
        
        # å› å­è½½è·çŸ©é˜µ
        st.markdown("#### å› å­è½½è·çŸ©é˜µ")
        st.dataframe(results["factor_loadings"], use_container_width=True)
        
        # æ–¹å·®è§£é‡Šç‡
        if "variance_explained" in results:
            st.markdown("#### æ–¹å·®è§£é‡Šç‡")
            variance_df = pd.DataFrame({
                "å› å­": [f"Factor_{i+1}" for i in range(len(results["variance_explained"]))],
                "è§£é‡Šæ–¹å·®": results["variance_explained"],
                "ç´¯è®¡æ–¹å·®": results.get("cumulative_variance", [])
            })
            st.dataframe(variance_df, use_container_width=True)
        
        # AIåˆ†æ
        if "ai_analysis" in results:
            renderer._render_ai_analysis_section(results["ai_analysis"])
    
    else:
        # é€šç”¨ç»“æœå±•ç¤º
        st.markdown("### ğŸ“ˆ åˆ†æç»“æœ")
        
        # æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„ç»“æœ
        for key, value in results.items():
            if key != "ai_analysis":
                st.markdown(f"#### {key}")
                if isinstance(value, pd.DataFrame):
                    st.dataframe(value, use_container_width=True)
                elif isinstance(value, (dict, list)):
                    st.json(value)
                else:
                    st.write(value)
        
        # AIåˆ†æï¼ˆå¦‚æœæœ‰ï¼‰
        if "ai_analysis" in results:
            renderer._render_ai_analysis_section(results["ai_analysis"])
    
    # æ·»åŠ ç»“æœå¯¼å‡ºåŠŸèƒ½
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“Š å¯¼å‡ºå›¾è¡¨"):
            st.success("å›¾è¡¨å¯¼å‡ºåŠŸèƒ½å¼€å‘ä¸­")
    
    with col2:
        if st.button("ğŸ“„ å¯¼å‡ºè¡¨æ ¼"):
            st.success("è¡¨æ ¼å¯¼å‡ºåŠŸèƒ½å¼€å‘ä¸­")
    
    with col3:
        if st.button("ğŸ“ ç”ŸæˆæŠ¥å‘Š"):
            st.success("æŠ¥å‘Šç”ŸæˆåŠŸèƒ½å·²åœ¨ç¬¬6æ­¥æä¾›")